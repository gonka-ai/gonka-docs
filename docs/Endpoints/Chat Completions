# Chat Completions
Learn how to use WeAI's Core API endpoint to get responses from language models.

To use one of these models via the WeAI API, you’ll send a request to the Chat Completions API containing the inputs and your API key, and receive a response containing the model’s output.

You can experiment with various models in the chat playground. If you’re not sure which model to use then try `llama3.1-405` if you need high intelligence or `llama3.1.-8` if you need the fastest speed and lowest cost.