# Hardware Specifications

Criteria: Nvidia GPUs belonging to generations after Tesla, with a minimum of 16 GB VRAM, and suitable for inference of Llama-3 (8B) in FP16.

| NVIDIA GPU         | Release Date  | VRAM           | Architecture | Generation            |
|---------------------|---------------|----------------|--------------|-----------------------|
| RTX 3090           | September 2020 | 24 GB GDDR6X   | Ampere       | RTX 30 Series        |
| A100               | May 2020       | 40 GB or 80 GB HBM2e | Ampere | A100                |
| RTX A6000          | December 2020  | 48 GB GDDR6    | Ampere       | RTX 30 Series        |
| A30                | 2021           | 24 GB HBM2     | Ampere       | A30                 |
| A10                | 2021           | 24 GB GDDR6    | Ampere       | A10                 |
| A40                | 2021           | 48 GB GDDR6    | Ampere       | A40                 |
| L40                | 2022           | 48 GB GDDR6    | Ada Lovelace | L-Series (Data Center) |
| H100               | May 2022       | 80 GB HBM3     | Hopper       | H100 (Data Center)   |
| RTX 4090           | October 2022   | 24 GB GDDR6X   | Ada Lovelace | RTX 40 Series        |
| RTX 6000 Ada Gen   | December 2022  | 48 GB GDDR6    | Ada Lovelace | RTX 40 Series        |
| L4                 | March 2023     | 24 GB GDDR6    | Ada Lovelace | L-Series (Data Center) |
| H200               | 2024           | 141 GB of HBM3e| Hopper       | H100 (Data Center)   |
